<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Neural Networks | Machine Learning</title>
<link href="../assets/lib/bootstrap-3.2.0/css/bootstrap.min.css" media="screen" rel="stylesheet" type="text/css">
<link href="../assets/stylesheets/style.css" media="screen" rel="stylesheet" type="text/css">
<link href="../assets/stylesheets/github.css" media="screen" rel="stylesheet" type="text/css">
<script src="../assets/lib/jquery-1.11.1/jquery.min.js"></script>
<script src="../assets/lib/bootstrap-3.2.0/js/bootstrap.min.js"></script>
<script src="../assets/javascripts/jquery.toctree.js"></script>
<script>

(function($) {

    $(function() {
        $('#toc').toctree({ selector:'#content :header', offset:1, depth:3 });
    });

})(window.jQuery);

</script>
</head>
<body>
<div id="wrapper">
    <div id="header">
    <div class="navbar navbar-static-top navbar-inverse">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#jsNavbarCollapse-1">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../index.html">Wiki</a>
        </div>
        <div class="collapse navbar-collapse" id="jsNavbarCollapse-1">
          <ul class="nav navbar-nav">
            <li><a href="./index.html">Machine Learning</a></li>
          </ul>
          <form class="navbar-form navbar-right" action="http://www.google.com/search" style="box-shadow: none; border: none">
  <input type="hidden" name="as_sitesearch" value="tachesimazzoca.github.io/wiki">
  <div class="form-group">
    <div class="input-group">
      <div class="input-group-addon" style="background: transparent; border-color: #333">
        <span class="glyphicon glyphicon-search"></span>
      </div>
      <input type="text" class="form-control" name="as_q" placeholder="Search">
    </div>
  </div>
</form>

        </div>
      </div>
    </div>
  </div>
  <!--/#header-->


  <div id="main">
    <div class="container-fluid">
      <ul class="breadcrumb">
        <li><a href="./index.html">Machine Learning</a></li><li>Neural Networks</li>
      </ul>
    </div>
    <div class="container-fluid">
      <div class="row">
        <div class="col-md-3 col-sm-4 hidden-xs">
          <div id="navigation">
            <div class="panel panel-default">
              <div class="panel-heading">
                <h3 class="panel-title" style="text-align: center; font-size: 11px; text-transform: uppercase; color: #999">Table of Contents</h3>
              </div>
              <div class="panel-body">
              <ul class="nav nav-pills nav-stacked"><li><a href="./overview.html">Overview</a></li><li><a href="./linear_regression.html">Linear Regression</a></li><li><a href="./logistic_regression.html">Logistic Regression</a></li><li><a href="./regularization.html">Regularization</a></li><li class="active"><a href="./neural_networks.html">Neural Networks</a></li></ul>
              </div>
            </div>
          </div>
        </div>
        <div class="col-md-9 col-sm-8">
          
          <div class="btn-group pull-right">
            <a class="btn btn-default" href="https://raw.github.com/tachesimazzoca/wiki/master/src/machine_learning/neural_networks.md">Raw</a>
            <a class="btn btn-default" href="https://github.com/tachesimazzoca/wiki/blame/master/src/machine_learning/neural_networks.md">Blame</a>
            <a class="btn btn-default" href="https://github.com/tachesimazzoca/wiki/commits/master/src/machine_learning/neural_networks.md">History</a>
          </div>
          <div id="content">
          <h1>Neural Networks</h1>
          <div id="toc">
          </div>
          <script type="text/x-mathjax-config">
  MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ["\\(","\\)"]] } });
</script>


<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>


<h2>Sigmoid Activation Function</h2>

<p>入力とパラメータの内積を、シグモイド関数を通して <code>0 &lt; a &lt; 1</code> の範囲に変換するモデルを、 <em>Sigmoid (Logistic) activation function</em> と呼ぶ。</p>

<script type="math/tex; mode=display" id="MathJax-Element-logistic_unit">
g(z) = \frac{1}{1 + e^{-z} } \\
h_{\theta}(x) = g({\theta}^{T} x) \\
</script>


<p>バイアス項 <em>Bias unit</em> として、<code>x(0) = 1</code> で固定し、<code>theta(0)</code> をオフセット値とする。入力値 <code>x</code> を <code>(0|1)</code> に制限すると、<code>theta</code> の値に応じて AND / OR の論理回路を実現できる。</p>

<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span><span class="p">;</span> <span class="mi">0</span> <span class="mi">1</span><span class="p">;</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">;</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">];</span>
<span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="nb">ones</span><span class="p">(</span><span class="nb">length</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">X</span><span class="p">];</span>         <span class="c">% [1 0 0; 1 0 1; 1 1 0; 1 1 1]</span>

<span class="n">theta1</span> <span class="p">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">30</span><span class="p">;</span> <span class="mi">20</span><span class="p">;</span> <span class="mi">20</span><span class="p">];</span>              <span class="c">% AND gate</span>
<span class="n">z1</span> <span class="p">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">theta1</span><span class="p">;</span>                     <span class="c">% [-30; -10; -10; 10]</span>
<span class="n">h1</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z1</span><span class="p">);</span>                    <span class="c">% [0; 0; 0; 1]</span>

<span class="n">theta2</span> <span class="p">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">;</span> <span class="mi">20</span><span class="p">;</span> <span class="mi">20</span><span class="p">];</span>              <span class="c">% OR gate</span>
<span class="n">z2</span> <span class="p">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">theta2</span><span class="p">;</span>                     <span class="c">% [-10; 10; 10; 30]</span>
<span class="n">h2</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">);</span>                    <span class="c">% [0; 1; 1; 1]</span></code></pre></div>


<h2>Forward Propagation</h2>

<p><em>Activation function</em> を複数レイヤーに定義し、各レイヤーの出力を次のレイヤーへの入力とすることで、より複雑な論理回路を実現できる。このモデルは、神経回路のシミュレーションを元にしており、ニューラルネットワーク <em>Neural network</em> と呼ばれる。</p>

<pre><code>   L1    |    L2    |    L3    |    L4
------------------------------------------
    [+1]-+     [+1]-+     [+1]-+
         |          |          |
  [x(1)]-+-&gt;[a2(1)]-+-&gt;[a3(1)]-+-&gt;[a4(1)]-&gt; h(x)
         |          |          |
  [x(2)]-+-&gt;[a2(2)]-+-&gt;[a3(2)]-+
         |          |
         +-&gt;[a2(3)]-+
</code></pre>

<script type="math/tex; mode=display" id="MathJax-Element-neural_network_layer2">
\begin{align}
\text{Input} \quad & \left\{
  \begin{array}{l l}
    x_0 = 1 \\
    x_1 \in \mathbb{R} \\
    x_2 \in \mathbb{R} \\
  \end{array}
\right. \\

\text{Layer1} \quad & \left\{
  \begin{array}{l l}
    {\Theta}^{(1)} \in \mathbb{R}^{3 \times 3} \\
    a^{(2)}_0 = 1 \\
    a^{(2)}_{1} = g({ {\Theta}^{(1)}_{1,0} } x_0 + { {\Theta}^{(1)}_{1,1} } x_1 + { {\Theta}^{(1)}_{1,2} x_2 }) \\
    a^{(2)}_{2} = g({ {\Theta}^{(1)}_{2,0} } x_0 + { {\Theta}^{(1)}_{2,1} } x_1 + { {\Theta}^{(1)}_{2,2} x_2 }) \\
    a^{(2)}_{3} = g({ {\Theta}^{(1)}_{3,0} } x_0 + { {\Theta}^{(1)}_{3,1} } x_1 + { {\Theta}^{(1)}_{3,2} x_2 }) \\
  \end{array}
\right. \\

\text{Layer2} \quad & \left\{
  \begin{array}{l l}
    {\Theta}^{(2)} \in \mathbb{R}^{2 \times 4} \\
    a^{(3)}_0 = 1 \\
    a^{(3)}_{1} = g({\Theta}^{(2)}_{1,0} a^{(2)}_0 + {\Theta}^{(2)}_{1,1} a^{(2)}_1 + {\Theta}^{(2)}_{1,2} a^{(2)}_2 + {\Theta}^{(2)}_{1,3} a^{(2)}_3) \\
    a^{(3)}_{2} = g({\Theta}^{(2)}_{2,0} a^{(2)}_0 + {\Theta}^{(2)}_{2,1} a^{(2)}_1 + {\Theta}^{(2)}_{2,2} a^{(2)}_2 + {\Theta}^{(2)}_{2,3} a^{(2)}_3) \\
  \end{array}
\right. \\

\text{Layer3} \quad & \left\{
  \begin{array}{l l}
    {\Theta}^{(3)} \in \mathbb{R}^{1 \times 3} \\
    a^{(4)}_1 = g({\Theta}^{(3)}_{1,0} a^{(3)}_0 + {\Theta}^{(3)}_{1,1} a^{(3)}_1 + {\Theta}^{(3)}_{1,2} a^{(3)}_2) \\
    h_{\Theta}(x) = a^{(4)}_1 \\
  \end{array}
\right. \\

\end{align}
</script>


<ul>
<li>入力 <code>x</code> のバイアス項として <code>x(0) = 1</code> とする。</li>
<li>Layer1: ３つの入力 <code>x</code> から、３つの出力 <code>a2</code> を算出する。バイアス項として <code>a2(0) = 1</code> とする。</li>
<li>Layer2: Layer1 の４つの出力 <code>a2</code> を入力とし、２つの出力 <code>a3</code> を算出する。バイアス項として <code>a3(0) = 1</code> とする。</li>
<li>Layer3: Layer2 の３つの出力 <code>a3</code> を入力とし、１つの出力 <code>a4</code> を算出する。</li>
<li>最終レイヤーの出力 <code>a4(1)</code> が、予測値 <code>h(x)</code> となる。</li>
</ul>


<p>Layer2 の２入力に NAND / OR ゲート、Layer3 の１入力に AND ゲートを置くことで、XOR ゲートとして機能する。</p>

<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">Theta1</span> <span class="p">=</span> <span class="p">[</span><span class="mi">30</span> <span class="o">-</span><span class="mi">20</span> <span class="o">-</span><span class="mi">20</span><span class="p">;</span> <span class="o">-</span><span class="mi">10</span> <span class="mi">20</span> <span class="mi">20</span><span class="p">];</span>    <span class="c">% [{NAND}; {OR}]</span>
<span class="n">Theta2</span> <span class="p">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">30</span> <span class="mi">20</span> <span class="mi">20</span><span class="p">];</span>                <span class="c">% [{AND}]</span>

<span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span><span class="p">;</span> <span class="mi">0</span> <span class="mi">1</span><span class="p">;</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">;</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">];</span>
<span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="nb">ones</span><span class="p">(</span><span class="nb">length</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">X</span><span class="p">];</span>         <span class="c">% [1 0 0; 1 0 1; 1 1 0; 1 1 1]</span>

<span class="n">z1</span> <span class="p">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">Theta1</span><span class="o">&#39;</span><span class="p">;</span>                    <span class="c">% [30 -10; 10 10; 10 10; -10 30]</span>
<span class="n">a2</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z1</span><span class="p">);</span>                    <span class="c">% [1 0; 1 1; 1 1; 0 1]</span>
<span class="n">a2</span> <span class="p">=</span> <span class="p">[</span><span class="nb">ones</span><span class="p">(</span><span class="nb">length</span><span class="p">(</span><span class="n">a2</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">a2</span><span class="p">];</span>      <span class="c">% [1 1 0; 1 1 1; 1 1 1; 1 0 1]</span>

<span class="n">z2</span> <span class="p">=</span> <span class="n">a2</span> <span class="o">*</span> <span class="n">Theta2</span><span class="o">&#39;</span><span class="p">;</span>                   <span class="c">% [-10; 10; 10; -10]</span>
<span class="n">a3</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">);</span>                    <span class="c">% [0; 1; 1; 0]</span></code></pre></div>


<p>このように、複数レイヤーの入出力を介して、前方に伝播させていく方法を <em>Forward propagation</em> と呼ぶ。</p>

<h2>Multi-class Classification</h2>

<p>３つ以上に分類するには、出力レイヤーのユニットを、分類の数だけ用意すればよい。</p>

<pre><code>   L1    |    L2    |    L3    |
--------------------------------
    [+1]-+     [+1]-+
         |          |
  [x(1)]-+-&gt;[a2(1)]-+-&gt;[a3(1)]
         |          |
  [x(2)]-+-&gt;[a2(2)]-+-&gt;[a3(2)]
         |          |
         +-&gt;[a2(3)]-+-&gt;[a3(3)]
         |          |
         +-&gt;[a2(4)]-+
</code></pre>

<p>出力レイヤーのベクトルを <code>a3</code>、正解値を <code>y</code> としたとき、<code>a3(y)</code> のフラグが立つと考える。</p>

<ul>
<li><code>y = 1 if a3 = [1; 0; 0]</code></li>
<li><code>y = 2 if a3 = [0; 1; 0]</code></li>
<li><code>y = 3 if a3 = [0; 0; 1]</code></li>
</ul>


<p>分類数を <code>K</code> とすると、費用関数は各出力の誤差平均を求めればよい。</p>

<script type="math/tex; mode=display" id="MathJax-Element-backprop_cost">
a = h_{\Theta}(x) \in \mathbb{R}^{K}\\
J(\Theta) = \frac{1}{m} {\sum_{i=1}^{m}} {\sum_{k=1}^{K}} [ -log(a_{i,k})(y_{i,k}) - log(1 - a_{i,k}) (1 - y_{i,k}) ] \\
</script>


<h2>Cost Function</h2>

<p>ニューラルネットワークの費用関数は、ロジスティック回帰と同様であるが、予測値を求めるには <em>Forward propagation</em> で各レイヤーを通して算出する必要がある。</p>

<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">Theta1</span> <span class="p">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">30</span> <span class="mi">10</span> <span class="mi">10</span> <span class="mi">10</span><span class="p">;</span> <span class="o">-</span><span class="mi">10</span> <span class="mi">20</span> <span class="mi">20</span> <span class="mi">20</span><span class="p">;</span> <span class="mi">20</span> <span class="o">-</span><span class="mi">10</span> <span class="o">-</span><span class="mi">10</span> <span class="o">-</span><span class="mi">10</span><span class="p">;</span> <span class="o">-</span><span class="mi">20</span> <span class="mi">10</span> <span class="mi">10</span> <span class="mi">10</span><span class="p">];</span>
<span class="n">Theta2</span> <span class="p">=</span> <span class="p">[</span><span class="mi">10</span> <span class="o">-</span><span class="mi">20</span> <span class="o">-</span><span class="mi">20</span> <span class="o">-</span><span class="mi">10</span> <span class="o">-</span><span class="mi">10</span><span class="p">;</span> <span class="o">-</span><span class="mi">10</span> <span class="mi">10</span> <span class="mi">10</span> <span class="mi">0</span> <span class="mi">10</span><span class="p">;</span> <span class="mi">20</span> <span class="o">-</span><span class="mi">20</span> <span class="o">-</span><span class="mi">20</span> <span class="o">-</span><span class="mi">10</span> <span class="o">-</span><span class="mi">10</span><span class="p">];</span>
<span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">;</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span><span class="p">;</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">;</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">];</span>
<span class="n">m</span> <span class="p">=</span> <span class="nb">size</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>

<span class="n">a1</span> <span class="p">=</span> <span class="n">X</span><span class="p">;</span>                         <span class="c">% 4 x 3</span>
<span class="n">a1</span> <span class="p">=</span> <span class="p">[</span><span class="nb">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="n">a1</span><span class="p">];</span>           <span class="c">% 4 x 4</span>
<span class="n">z2</span> <span class="p">=</span> <span class="n">a1</span> <span class="o">*</span> <span class="n">Theta1</span><span class="o">&#39;</span><span class="p">;</span>              <span class="c">% 4 x 4</span>
<span class="n">a2</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">);</span>
<span class="n">a2</span> <span class="p">=</span> <span class="p">[</span><span class="nb">ones</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span> <span class="n">a2</span><span class="p">];</span> <span class="c">% 4 x 5</span>
<span class="n">z3</span> <span class="p">=</span> <span class="n">a2</span> <span class="o">*</span> <span class="n">Theta2</span><span class="o">&#39;</span><span class="p">;</span>              <span class="c">% 4 x 3</span>
<span class="n">h</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z3</span><span class="p">);</span></code></pre></div>


<p><em>Regularization</em> を行なう場合は、各レイヤーにパラメータがある点に注意する。バイアス項は除外する。</p>

<script type="math/tex; mode=display" id="MathJax-Element-backprop_cost_reg">
\text{$L = $ the number of the layers} \\
\text{$sl = $ the number of parameters of the layer $l$} \\
J(\Theta) = J(\Theta) + \frac{\lambda}{2m} \sum_{l=1}^{L-1} \sum_{i=1}^{sl} \sum_{j=1}^{sl+1} ({\Theta}_{j,i}^{(l)})^2 \\
</script>




<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">t1</span> <span class="p">=</span> <span class="n">Theta1</span><span class="p">;</span>
<span class="n">t2</span> <span class="p">=</span> <span class="n">Theta2</span><span class="p">;</span>
<span class="n">t1</span><span class="p">(:,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">t2</span><span class="p">(:,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">=</span> <span class="mi">0</span><span class="p">;</span>

<span class="n">lambda</span> <span class="p">=</span> <span class="mf">0.1</span><span class="p">;</span>
<span class="n">J</span> <span class="p">=</span> <span class="n">J</span> <span class="o">+</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">t1</span> <span class="o">.^</span> <span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">t2</span> <span class="o">.^</span> <span class="mi">2</span><span class="p">)))</span> <span class="o">*</span> <span class="n">lambda</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">);</span></code></pre></div>


<h2>Sigmoid Gradient Function</h2>

<p>ネイピア数 <code>e</code> を底とする指数の微分は <code>(e^x)' = e^x</code> であることを利用して、シグモイド関数 <code>g(z)</code> を微分すると <code>g'(z) = g(z) * (1 - g(z))</code> となる。</p>

<script type="math/tex; mode=display" id="MathJax-Element-sigmoid_partial_simplify">
g(z) = \frac{1}{1 + e^{-z}} \\

\begin{align}

& \left\{
\begin{array}{l l}
x = -z \\
u = 1 + e^{x} \\
g'(u) = (u^{-1})' = -1 \cdot u^{-2} = -(1 + e^{-z})^{-2} \\
u' = (1 + e^{x})' = (e^{x})'(-z)' = (e^{x})(-1) = -e^{-z} \\
\end{array}
\right. \\

\end{align} \\

</script>


<script type="math/tex; mode=display" id="MathJax-Element-sigmoid_gradient">
\begin{align}
g'(z) & = g'(u) \cdot u' = -(1 + e^{-z})^{-2} \cdot -e^{-z}\\
      & = \frac{e^{-z}}{(1 + e^{-z})^2} \\
      & = \frac{1}{1 + e^{-z}} \left( \frac{1 + e^{-z}}{1 + e^{-z}} - \frac{1}{1 + e^{-z}} \right) \\
      & = \frac{1}{1 + e^{-z}} \left( 1 - \frac{1}{1 + e^{-z}} \right) \\
      & = g(z)(1 - g(z)) \\
g'(0) & = g(0)(1 - g(0)) = 0.5 \cdot 0.5 = 0.25 \\
\end{align} \\
</script>


<h2>Backpropagation</h2>

<p>ニューラルネットワークの各ユニットのパラメータを求めるには、ロジスティック回帰と同様に勾配法を用いる。各ユニットの偏微分を求めるために、最終出力の誤差から各レイヤーを逆に伝播して算出する必要がある。この方法を、誤差逆伝播法 <em>Backpropagation</em> と呼ぶ。</p>

<p>出力レイヤーの誤差は、予測値ベクトルから正解値ベクトルを引いたものになる。</p>

<script type="math/tex; mode=display" id="MathJax-Element-backprop_error_output">
\delta^{(L)}_{k} = a^{(L)}_{k} - y_{k}\\
</script>


<p>各中間レイヤーの誤差は以下の式で求められる。各パラメータ自身が次のレイヤーに伝播させてしまった誤差を算出すると考えればよい。</p>

<script type="math/tex; mode=display" id="MathJax-Element-backprop_error_hidden">
\delta^{(l)} = ({\Theta}^{(l)})^{T} \delta^{(l+1)} .* g'(z^{(l)}) \\

\left\{
  \begin{array}{l l}
    \delta^{(l)}_1 = ({\Theta}^{(l)}_{1,1} \delta^{(l+1)}_{1} + {\Theta}^{(l)}_{2,1} \delta^{(l+1)}_{2} + {\Theta}^{(l)}_{3,1} \delta^{(l+1)}_{3} \ldots) g'(z^{(l)}_1) \\
    \delta^{(l)}_2 = ({\Theta}^{(l)}_{1,2} \delta^{(l+1)}_{1} + {\Theta}^{(l)}_{2,2} \delta^{(l+1)}_{2} + {\Theta}^{(l)}_{3,2} \delta^{(l+1)}_{3} \ldots) g'(z^{(l)}_2) \\
    \delta^{(l)}_3 = ({\Theta}^{(l)}_{1,3} \delta^{(l+1)}_{1} + {\Theta}^{(l)}_{2,3} \delta^{(l+1)}_{2} + {\Theta}^{(l)}_{3,3} \delta^{(l+1)}_{3} \ldots) g'(z^{(l)}_3) \\
  \end{array} \\
\right. \\
</script>


<p>各ユニットの出力に直後のレイヤーの誤差を掛け合わせたものが、各パラメータの偏微分となる。</p>

<script type="math/tex; mode=display" id="MathJax-Element-backprop_grad">
\Delta^{(l)} = \Delta^{(l)} + \delta^{(l+1)}(a^{(l)})^{T} \\
\frac{\partial J(\Theta)}{\partial \Theta^{(l)}_{i,j}} = a^{(l)}_{j} \delta^{(l+1)}_{i} = \frac{1}{m} \Delta^{(l)}_{i,j} \\
</script>


          </div>
          
        </div>
      </div>
    </div>
  </div>
  <!--/#main-->
  <div id="footer">
<div class="container-fluid">
  <div class="row">
    <div class="col-md-12">
      <dl class="dl-horizontal pull-right">
        <dt><span class="muted">Repository</span></dt>
        <dd><a href="https://github.com/tachesimazzoca/wiki">tachesimazzoca/wiki</a></dd>
        <dt><span class="muted">Author</span></dt>
        <dd><a href="https://github.com/tachesimazzoca">@tachesimazzoca</a></dd>
      </dl>
    </div>
  </div>
</div>
</div>
<!--/#footer-->

</div>
<!--/#wrapper-->
<!--Google Analytics-->
<script type="text/javascript">

if ("tachesimazzoca.github.io" == location.hostname) {

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35398490-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
}

</script>
<!--/Google Analytics-->

</body>
</html>

