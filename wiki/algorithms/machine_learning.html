<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Machine Learning | Algorithms</title>
<link href="../assets/lib/bootstrap-3.2.0/css/bootstrap.min.css" media="screen" rel="stylesheet" type="text/css">
<link href="../assets/stylesheets/style.css" media="screen" rel="stylesheet" type="text/css">
<link href="../assets/stylesheets/github.css" media="screen" rel="stylesheet" type="text/css">
<script src="../assets/lib/jquery-1.11.1/jquery.min.js"></script>
<script src="../assets/lib/bootstrap-3.2.0/js/bootstrap.min.js"></script>
<script src="../assets/javascripts/jquery.toctree.js"></script>
<script>

(function($) {

    $(function() {
        $('#toc').toctree({ selector:'#content :header', offset:1, depth:3 });
    });

})(window.jQuery);

</script>
</head>
<body>
<div id="wrapper">
    <div id="header">
    <div class="navbar navbar-static-top navbar-inverse">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#jsNavbarCollapse-1">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../index.html">Wiki</a>
        </div>
        <div class="collapse navbar-collapse" id="jsNavbarCollapse-1">
          <ul class="nav navbar-nav">
            <li><a href="./index.html">Algorithms</a></li>
          </ul>
          <form class="navbar-form navbar-right" action="http://www.google.com/search" style="box-shadow: none; border: none">
  <input type="hidden" name="as_sitesearch" value="tachesimazzoca.github.io/wiki">
  <div class="form-group">
    <div class="input-group">
      <div class="input-group-addon" style="background: transparent; border-color: #333">
        <span class="glyphicon glyphicon-search"></span>
      </div>
      <input type="text" class="form-control" name="as_q" placeholder="Search">
    </div>
  </div>
</form>

        </div>
      </div>
    </div>
  </div>
  <!--/#header-->


  <div id="main">
    <div class="container-fluid">
      <ul class="breadcrumb">
        <li><a href="./index.html">Algorithms</a></li><li>Machine Learning</li>
      </ul>
    </div>
    <div class="container-fluid">
      <div class="row">
        <div class="col-md-3 col-sm-4 hidden-xs">
          <div id="navigation">
            <div class="panel panel-default">
              <div class="panel-heading">
                <h3 class="panel-title" style="text-align: center; font-size: 11px; text-transform: uppercase; color: #999">Table of Contents</h3>
              </div>
              <div class="panel-body">
              <ul class="nav nav-pills nav-stacked"><li class="active"><a href="./machine_learning.html">Machine Learning</a></li></ul>
              </div>
            </div>
          </div>
        </div>
        <div class="col-md-9 col-sm-8">
          
          <div class="btn-group pull-right">
            <a class="btn btn-default" href="https://raw.github.com/tachesimazzoca/wiki/master/src/algorithms/machine_learning.md">Raw</a>
            <a class="btn btn-default" href="https://github.com/tachesimazzoca/wiki/blame/master/src/algorithms/machine_learning.md">Blame</a>
            <a class="btn btn-default" href="https://github.com/tachesimazzoca/wiki/commits/master/src/algorithms/machine_learning.md">History</a>
          </div>
          <div id="content">
          <h1>Machine Learning</h1>
          <div id="toc">
          </div>
          <script type="text/x-mathjax-config">
  MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ["\\(","\\)"]] } });
</script>


<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>


<h2>Definition</h2>

<p>Arthur Samuel (1959) - Machine Learning:</p>

<blockquote><p>Field of study that gives computers the ability to learn without being explicitly programmed.</p></blockquote>

<p>Tom Mitchell (1998) - Well-posed Learning:</p>

<blockquote><p>A computer program is said to learn from experience E with respect to some task T
and some performance measure P, if its performance on T, as measured by P, improves with experience E.</p></blockquote>

<p>スパムメール判定</p>

<ul>
<li>E(xperience): メールをスパムとして振り分ける</li>
<li>T(ask): メールをスパムとして分類する</li>
<li>P(erformance): 振り分けたメールがスパムである確率</li>
</ul>


<p>対戦ゲーム</p>

<ul>
<li>E(xperience): ゲームをする（次の手を決める）</li>
<li>T(ask): ゲームに勝つ</li>
<li>P(erformance): ゲームに勝つ確率</li>
</ul>


<h3>Classification Problem vs. Regression Problem</h3>

<p><em>Classification Problem</em> は、<code>(YES|NO)</code> や <code>(A|B|C)</code> のように区分された値 <em>Discrete-value</em> に分類する問題を指す。</p>

<ul>
<li>過去の対戦成績から、勝敗を予測する</li>
<li>オーディオデータから、ボーカル曲かどうかを判定する</li>
<li>腫瘍の大きさから、良性か悪性かを予測する</li>
</ul>


<p><em>Regression Problem</em> は、連続値 <em>Continuous-value</em> すなわち、量を求める問題を指す。数は整数値として考えれば、区切られているように感じてしまうが、単に取引上の単位であって、実際には境界のない連続値である。</p>

<ul>
<li>部屋の大きさから、家賃を予測する</li>
<li>過去の雨量データから、降水量を予測する</li>
<li>過去実績から、売上げを予測する</li>
</ul>


<h3>Supervised Learning vs. Unsupervised Learning</h3>

<p><em>Supervised Learning</em> は、予め正解（分類）が分かっていて、その分類に振り分ける手法になる。</p>

<ul>
<li>真偽 / 勝敗 / 可否</li>
<li>性別</li>
<li>ラベル（重要|通常|スパム）</li>
</ul>


<p><em>Unupervised Learning</em> は、正解（分類）自体が定義されていない状態から、分類を抽出していく手法になる。</p>

<ul>
<li>記事内容から、同種の記事を見つける（記事のカテゴリは不定）</li>
<li>行動パターンから、似ているユーザ同士を見つける（どのようなユーザかは不定）</li>
<li>投薬結果から、同症状を引き起こす患者同士を見つける（どのような副作用を起こすかは不定）</li>
</ul>


<h2>Linear Regression</h2>

<h3>Cost Function</h3>

<ul>
<li><code>x</code> から <code>y</code> を導く <code>m</code> 個の訓練データ <em>Training Set</em> があるとする。例) x: 部屋の広さ, y: 家賃</li>
<li><code>y</code> を予測する関数を <code>h(x) = a + b * x</code> とする。</li>
<li><code>h(x) - y</code> すなわち <code>(a + b * x) - y</code> が予測との誤差になる。</li>
</ul>


<p>各データ毎の誤差の二乗したものの総和を、「二乗誤差」 <em>Squared Error</em> と呼ぶ。この値が小さい程、予測との誤差が少ないことになる。この値を元に、費用関数 <em>Cost Function</em> を定義して、最適値を見つけていく。</p>

<p>例として、以下の費用関数 <code>J(a, b)</code> を定義し、訓練データ <code>x = [1; 2; 3], y = [2; 4; 6]</code> を適用してみる。</p>

<script type="math/tex; mode=display" id="MathJax-Element-hypothesis">
h(x) = a + bx
</script>


<script type="math/tex; mode=display" id="MathJax-Element-mse">
J(a, b) = \frac{1}{2m} {\sum_{i=1}^{m} (h(x_i)-y_i)^2}
</script>


<script type="math/tex; mode=display" id="MathJax-Element-cost_function1">
J(1, 1) = \frac{(2 - 2)^2 + (3 - 4)^2 + (4 - 6)^2}{2 \cdot 3} = 0.83333 \ldots
</script>


<script type="math/tex; mode=display" id="MathJax-Element-cost_function2">
J(0, 2) = \frac{(2 - 2)^2 + (4 - 4)^2 + (6 - 6)^2}{2 \cdot 3} = 0
</script>


<p><code>a = 0, b = 2</code> すなわち <code>h(x) = 2 * x</code> が、最適な線形回帰モデル <em>Linear Regression Model</em> になる。</p>

<p>この訓練データ内では誤差はないが、今後のあらゆるケースで、誤差なく予測できるわけではない。あくまで訓練データ内で誤差がないというだけである。言い替えると、訓練データに関しては、誤差なく予測することができる。</p>

<ul>
<li>訓練データに含まれない <code>x = 4</code> が、必ず <code>y = h(x) = 2 * 4 = 8</code> という結果になるわけではない。</li>
<li>今後の入力データが、訓練データに含まれる <code>x = 2</code> であったとしても、必ず <code>y = h(x) = 2 * 2 = 4</code> という結果になるわけではない。</li>
</ul>


<h3>Gradient Decent</h3>

<p>線形回帰モデルを見つけるには、勾配法 <em>Gradient decent</em> を用いることができる。</p>

<p>勾配法は、反復法を用いて解に近づけていく。反復法の一つ、ニュートン法 <em>Newton's method</em> により平方根を見つける例をおさらいしてみる。</p>

<p><code>x</code> を平方根、<code>a</code> をその二乗としたとき</p>

<script type="math/tex; mode=display" id="MathJax-Element-newtons_method_f">
f(x) = x^2 - a
</script>


<p>を定義する。この関数を <code>y</code> 軸においたグラフにおいて、<code>x</code> 軸との交点 <code>(x, f(x) = 0)</code> の <code>x</code> が平方根になる。</p>

<p>この関数を微分した時の導関数 <code>f'(x)</code> は</p>

<script type="math/tex; mode=display" id="MathJax-Element-newtons_method_fd">
(x^n + C)' = nx^{n-1} \\
f'(x) = (f(x))' = (x^2 - a)' = 2x
</script>


<p>であるので、任意の <code>(x(i), f(x(i)))</code> を接点とする接線の傾きは、<code>f'(x(i)) = 2x(i)</code> であることがわかる。</p>

<p>直線の方程式は <em>「底辺 x = 高さ y / 傾き m」</em> であるので、この接線の <code>x</code> 軸との交点を <code>x(i+1)</code> とすると</p>

<script type="math/tex; mode=display" id="MathJax-Element-newtons_method_fd_line">
x_{i+1} = x_{i} - \frac{f(x_{i})}{f'(x_{i})} = x_{i} - \frac{x_{i}^2 - a}{2x_{i}}
</script>


<p>で求められる。この式を繰り返すことで、<code>x(i)</code> と <code>x(i+1)</code> が限りなく近づき、<code>x(i)</code> は <code>(x, f(x) = 0)</code> すなわち平方根に収束する。</p>

<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">octave</span><span class="o">&gt;</span> <span class="n">x</span> <span class="p">=</span> <span class="mi">1</span><span class="p">;</span>  <span class="c">% find out sqrt(3) by Newton&#39;s Method</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">x</span> <span class="p">=</span> <span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span>^<span class="mi">2</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="p">=</span>  <span class="mi">2</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">x</span> <span class="p">=</span> <span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span>^<span class="mi">2</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="p">=</span>  <span class="mf">1.7500</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">x</span> <span class="p">=</span> <span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span>^<span class="mi">2</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="p">=</span>  <span class="mf">1.7321</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">x</span> <span class="p">=</span> <span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span>^<span class="mi">2</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="p">=</span>  <span class="mf">1.7321</span></code></pre></div>


<p>線形回帰モデルの場合にも、同じような反復を繰り返して、最適値に収束させていけばよい。方法として、最急降下法 <em>Steepest descent method</em> がある。</p>

<p>仮説を <code>h(x) = a + b * x</code> とし、費用関数を <code>J(a, b)</code> とした時、<code>(a, b, J(a, b))</code> の三次元グラフを書くと、<code>J(a, b)</code> 軸で凹凸をもったグラフとなる。すなわち、この凹みの最も深い位置が、最も誤差の少ない最適値になる。</p>

<p>最急降下法では、以下の式で最適値を目指して勾配を下っていく。</p>

<script type="math/tex; mode=display" id="MathJax-Element-gradient_descent">
X_i := X_i - \alpha \left( {\partial f(X) \over \partial X_i} \right)
</script>


<ul>
<li><code>X</code> は n 次元のベクトル</li>
<li><code>α</code> は、どれだけ進むかの割合 <em>Learning rate</em> で、正の数（主に定数）をとる。</li>
<li>偏微分の項 <em>Derivative term</em> である <code>df(X) / dX(i)</code> は、費用関数 <code>f(X)</code> の最も変化の大きい方向に勾配ベクトルを向ける。</li>
<li>この式を反復して <code>X</code> を更新していく。勾配を下って凹みに向かって収束していくため、<code>α</code> が大きすぎなければ <code>f(X)</code> は必ず小さくなる。</li>
</ul>


<p>いかなる条件であっても、必ず最適値を見つけられるわけではない。</p>

<ul>
<li>複数の凹みがある場合、降下を始めた地点からたどり着く「局所的な最小値」 <em>Local minimum</em> になる。必ずしも「全域の最小値」 <em>Global minimum</em> ではない。</li>
<li><code>α</code> の値は、固定であっても、勾配を進む割合が一定というわけではない。</li>
<li><code>α</code> の値は、小さすぎると収束 <em>Converge</em> するまでに時間がかかりすぎてしまう。大きすぎると最小値を通り過ぎて、勾配を上ってしまうことになり、反復するほどに悪い解へと向かう発散 <em>Diverge</em> を引き起こす場合もある。</li>
</ul>


<p>訓練データ <code>x = [1; 2; 3]; y = [2; 4; 6]</code> の仮説 <code>h(x) = a + b * x</code> を、最急降下法で求めてみる。</p>

<p>入力データ <code>x</code> より、先頭列に固定値 <code>1</code> を置いた行列 <code>X</code> を作成する。</p>

<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">octave</span><span class="o">&gt;</span> <span class="n">x</span> <span class="p">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">;</span> <span class="mi">2</span><span class="p">;</span> <span class="mi">3</span><span class="p">];</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="nb">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="p">]</span>
<span class="n">X</span> <span class="p">=</span>

   <span class="mi">1</span>   <span class="mi">1</span>
   <span class="mi">1</span>   <span class="mi">2</span>
   <span class="mi">1</span>   <span class="mi">3</span></code></pre></div>


<p><code>h(x) = a + b * x</code> のパラメータ <code>a, b</code> 用に、ベクトル <code>theta</code> を作成する。<code>X(:,1) = 1</code> としておいたことで、行列の積 <code>X * theta</code> のみで、各入力データ行の <code>h(x)</code> が得られることが分かる。パラメータが増えた時は、<code>X</code> の各列と <code>theta</code> に追加するだけで良い。</p>

<script type="math/tex; mode=display" id="MathJax-Element-gradient_descent_hypothesis">
x_{0} = 1 \\
h(x) = \theta^T x = \theta_{0}x_{0} + \theta_{1}x_{1} + \ldots + \theta_{n}x_n
</script>




<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">octave</span><span class="o">&gt;</span> <span class="n">theta</span> <span class="p">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">;</span> <span class="mi">3</span><span class="p">];</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="o">*</span> <span class="n">theta</span>
<span class="n">ans</span> <span class="p">=</span>

    <span class="mi">5</span>
    <span class="mi">8</span>
   <span class="mi">11</span></code></pre></div>


<p>偏微分の項を 「全データの誤差の総和 x 各パラメータ入力 / データ数」として、全パラメータに対して、同時に最急降下法を行なっていく。</p>

<script type="math/tex; mode=display" id="MathJax-Element-gradient_descent_a">
\theta_{j} := \theta_{j} - \alpha \left(\frac{1}{m} \sum_{i=1}^{m} (h(X_{i}) - y_{i}) \cdot X_{i,j} \right)
</script>


<p><code>theta = [1; 1], alpha = 0.1</code> として反復していくと、<code>theta = [0; 2]</code> すなわち <code>h(x) = 2 * x</code> に収束していくことが分かる。　</p>

<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">octave</span><span class="o">&gt;</span> <span class="n">x</span> <span class="p">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">;</span> <span class="mi">2</span><span class="p">;</span> <span class="mi">3</span><span class="p">];</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">y</span> <span class="p">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">;</span> <span class="mi">4</span><span class="p">;</span> <span class="mi">6</span><span class="p">];</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="n">m</span> <span class="p">=</span> <span class="nb">size</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>          <span class="c">% number of rows</span>
<span class="n">m</span> <span class="p">=</span> <span class="mi">3</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="nb">ones</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="p">];</span>    <span class="c">% input data with intercept term 1</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">alpha</span> <span class="p">=</span> <span class="mf">0.1</span><span class="p">;</span>            <span class="c">% learniing rate</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">theta</span> <span class="p">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">;</span> <span class="mi">1</span><span class="p">];</span>         <span class="c">% parameters of hypothesis</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span>           <span class="c">% difference of each output</span>
<span class="n">ans</span> <span class="p">=</span>

   <span class="mi">0</span>
  <span class="o">-</span><span class="mi">1</span>
  <span class="o">-</span><span class="mi">2</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span>    <span class="c">% difference of each output * each input parameter</span>
<span class="n">ans</span> <span class="p">=</span>

  <span class="o">-</span><span class="mi">3</span>  <span class="o">-</span><span class="mi">8</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="n">theta</span> <span class="p">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="p">(((</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">.*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span><span class="o">&#39;</span>
<span class="n">theta</span> <span class="p">=</span>

   <span class="mf">1.1000</span>
   <span class="mf">1.2667</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="n">theta</span> <span class="p">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="p">(((</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">.*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span><span class="o">&#39;</span>
<span class="n">theta</span> <span class="p">=</span>

   <span class="mf">1.1367</span>
   <span class="mf">1.3889</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="k">for</span> <span class="n">i</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="mi">410</span><span class="p">,</span> <span class="n">theta</span> <span class="p">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="p">(((</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">.*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span><span class="o">&#39;</span><span class="p">;</span> <span class="k">end</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">theta</span>
<span class="n">theta</span> <span class="p">=</span>

   <span class="mf">0.0082757</span>
   <span class="mf">1.9963595</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="n">theta</span> <span class="p">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="p">(((</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">.*</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span><span class="o">&#39;</span>
<span class="n">theta</span> <span class="p">=</span>

   <span class="mf">0.0081763</span>
   <span class="mf">1.9964032</span></code></pre></div>


<h4>Feature Normalization</h4>

<p>各パラメータの変動範囲を統一することで、収束時間を短くすることができる。「(値 - 平均値) / 標準偏差」に正規化すると、概ね <em>-2 &lt; x &lt; 2</em> の範囲に収まる。</p>

<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="mi">45</span> <span class="mi">452000</span><span class="p">;</span> <span class="mi">24</span> <span class="mi">285000</span><span class="p">;</span> <span class="mi">53</span> <span class="mi">524000</span><span class="p">;</span> <span class="mi">35</span> <span class="mi">389000</span><span class="p">];</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">m</span> <span class="p">=</span> <span class="nb">size</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">m</span> <span class="p">=</span>  <span class="mi">4</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="p">=</span> <span class="n">X</span> <span class="o">-</span> <span class="p">(</span><span class="nb">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">mean</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">X</span> <span class="p">=</span>

   <span class="mf">5.7500e+00</span>   <span class="mf">3.9500e+04</span>
  <span class="o">-</span><span class="mf">1.5250e+01</span>  <span class="o">-</span><span class="mf">1.2750e+05</span>
   <span class="mf">1.3750e+01</span>   <span class="mf">1.1150e+05</span>
  <span class="o">-</span><span class="mf">4.2500e+00</span>  <span class="o">-</span><span class="mf">2.3500e+04</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="p">=</span> <span class="n">X</span> <span class="o">./</span> <span class="p">(</span><span class="nb">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">std</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">X</span> <span class="p">=</span>

   <span class="mf">0.45805</span>   <span class="mf">0.38983</span>
  <span class="o">-</span><span class="mf">1.21483</span>  <span class="o">-</span><span class="mf">1.25831</span>
   <span class="mf">1.09534</span>   <span class="mf">1.10041</span>
  <span class="o">-</span><span class="mf">0.33856</span>  <span class="o">-</span><span class="mf">0.23192</span></code></pre></div>


<h3>Normal Equations</h3>

<p>勾配法を用いずに、連立方程式で解を得る方法もある。連立方程式は以下のように行列で表すことができる。</p>

<script type="math/tex; mode=display" id="MathJax-Element-normaleq">
\left\{
  \begin{array}{l l}
ax + by = p \\
cx + dy = q \\
  \end{array}

\quad

\begin{bmatrix}
a & b \\
c & d \\
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
p \\
q \\
\end{bmatrix} \\

\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
a & b \\
c & d \\
\end{bmatrix}^{-1}
\begin{bmatrix}
p \\
q \\
\end{bmatrix} \\

\right.
</script>


<p>おなじ要領で、訓練データの行列を用いて、連立方程式を解けばよい。</p>

<script type="math/tex; mode=display" id="MathJax-Element-normaleq_matrices">
\theta =
\begin{bmatrix}
\theta_1 \\
\theta_2 \\
\vdots \\
\theta_{m} \\
\end{bmatrix}
,

X =
\begin{bmatrix}
x_{1,1} & x_{1,2} & \ldots & x_{1,n} \\
x_{2,1} & x_{2,2} & \ldots & x_{2,n} \\
\vdots & \vdots & \ddots & \vdots \\
x_{m,1} & x_{m,2} & \ldots & x_{m,n} \\
\end{bmatrix}
,
y =
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_{m} \\
\end{bmatrix}
</script>


<p>公式は <code>X^-1 * y</code> になるが、逆行列 <code>X^-1</code> を求めるには <code>m = n</code> の正方行列 <em>Square matrix</em> である必要がある。正方行列でない場合は、疑似逆行列 <em>Pseudo-inverse matrix</em> <code>(X^T * X)^-1 * X^T</code> を用いる。疑似逆行列の計算には、<em>O(n^3)</em> のコストがかかってしまうので、パラメータ数が多い場合は勾配法を使う。</p>

<script type="math/tex; mode=display" id="MathJax-Element-normaleq_matrices_formula">
\begin{align}
\theta & = X^{-1} y\\
\theta & = (X^T X)^{-1} X^T y \\
\end{align}
</script>




<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">1</span><span class="p">;</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">;</span> <span class="mi">1</span> <span class="mi">3</span><span class="p">];</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="n">y</span> <span class="p">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">;</span> <span class="mi">4</span><span class="p">;</span> <span class="mi">6</span><span class="p">];</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="nb">inv</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">error</span><span class="p">:</span> <span class="n">inverse</span><span class="p">:</span> <span class="n">argument</span> <span class="n">must</span> <span class="n">be</span> <span class="n">a</span> <span class="n">square</span> <span class="n">matrix</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="nb">inv</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">&#39;</span>      <span class="c">% pseudo-inverse matrix: [1.3333 0.3333 -0.6666; -0.5 0 0.5]</span>
<span class="n">ans</span> <span class="p">=</span>

   <span class="mf">1.3333e+00</span>   <span class="mf">3.3333e-01</span>  <span class="o">-</span><span class="mf">6.6667e-01</span>
  <span class="o">-</span><span class="mf">5.0000e-01</span>  <span class="o">-</span><span class="mf">2.2204e-16</span>   <span class="mf">5.0000e-01</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="nb">pinv</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>               <span class="c">% using pinv(x)</span>
<span class="n">ans</span> <span class="p">=</span>

   <span class="mf">1.3333e+00</span>   <span class="mf">3.3333e-01</span>  <span class="o">-</span><span class="mf">6.6667e-01</span>
  <span class="o">-</span><span class="mf">5.0000e-01</span>  <span class="o">-</span><span class="mf">4.8572e-16</span>   <span class="mf">5.0000e-01</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="nb">inv</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span>  <span class="c">% identity matrix: [1 0; 0 1]</span>
<span class="n">ans</span> <span class="p">=</span>

   <span class="mf">1.0000e+00</span>  <span class="o">-</span><span class="mf">5.3291e-15</span>
  <span class="o">-</span><span class="mf">6.6613e-16</span>   <span class="mf">1.0000e+00</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="nb">inv</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span>  <span class="c">% solution: [0; 2]</span>
<span class="n">ans</span> <span class="p">=</span>

  <span class="o">-</span><span class="mf">1.0658e-14</span>
   <span class="mf">2.0000e+00</span></code></pre></div>


<h4>Non-invertible Matrix</h4>

<p>行列が非可逆行列 <em>Non-invertible matrix (singular/degenerate)</em> である場合、解が存在しない（平行グラフである）か、式が重複している（同グラフである）ため、式を満たすあらゆる解が存在する。</p>

<script type="math/tex; mode=display" id="MathJax-Element-normaleq_noninvertible">
\left\{
  \begin{array}{l l}
6x + 2y & = 4 & \cdots y = 2 - 3x \\
3x +  y & = 1 & \cdots y = 1 - 3x \\
  \end{array}
\right.

\\

\left\{
  \begin{array}{l l}
6x + 2y & = 2 & \cdots y = 1 - 3x \\
3x +  y & = 1 & \cdots y = 1 - 3x \\
  \end{array}
\right. \\
</script>


<p>このように非可逆行列になるケースは以下がある。これらは、重複するパラメータを減らすことで解決できる。</p>

<ul>
<li><code>X = [1 2 4; 2 4 8; 3 6 12]</code> のように、単に各パラメータが一定率で変化している場合</li>
<li>訓練データ数 <code>m</code> が、パラメータ数 <code>n</code> より少ない場合</li>
</ul>


<div class="highlight"><pre><code class="language-octave" data-lang="octave"><span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="mi">6</span> <span class="mi">2</span><span class="p">;</span> <span class="mi">3</span> <span class="mi">1</span><span class="p">];</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="nb">inv</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">warning</span><span class="p">:</span> <span class="n">inverse</span><span class="p">:</span> <span class="n">matrix</span> <span class="n">singular</span> <span class="n">to</span> <span class="n">machine</span> <span class="n">precision</span><span class="p">,</span> <span class="nb">rcond</span> <span class="p">=</span> <span class="mi">0</span>
<span class="n">ans</span> <span class="p">=</span>

   <span class="nb">Inf</span>   <span class="nb">Inf</span>
   <span class="nb">Inf</span>   <span class="nb">Inf</span>

<span class="n">octave</span><span class="o">&gt;</span> <span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="mi">1</span> <span class="mi">10</span> <span class="mi">8</span><span class="p">;</span> <span class="mi">1</span> <span class="mi">23</span> <span class="o">-</span><span class="mi">8</span><span class="p">];</span>
<span class="n">octave</span><span class="o">&gt;</span> <span class="nb">inv</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">&#39;</span>
<span class="nb">warning</span><span class="p">:</span> <span class="n">inverse</span><span class="p">:</span> <span class="n">matrix</span> <span class="n">singular</span> <span class="n">to</span> <span class="n">machine</span> <span class="n">precision</span><span class="p">,</span> <span class="nb">rcond</span> <span class="p">=</span> <span class="mf">5.26926e-19</span>
<span class="n">ans</span> <span class="p">=</span>

   <span class="mf">0.000000</span>   <span class="mf">0.000000</span>
   <span class="mf">0.039062</span>   <span class="mf">0.039062</span>
   <span class="mf">0.078125</span>  <span class="o">-</span><span class="mf">0.031250</span></code></pre></div>




          </div>
          
        </div>
      </div>
    </div>
  </div>
  <!--/#main-->
  <div id="footer">
<div class="container-fluid">
  <div class="row">
    <div class="col-md-12">
      <dl class="dl-horizontal pull-right">
        <dt><span class="muted">Repository</span></dt>
        <dd><a href="https://github.com/tachesimazzoca/wiki">tachesimazzoca/wiki</a></dd>
        <dt><span class="muted">Author</span></dt>
        <dd><a href="https://github.com/tachesimazzoca">@tachesimazzoca</a></dd>
      </dl>
    </div>
  </div>
</div>
</div>
<!--/#footer-->

</div>
<!--/#wrapper-->
<!--Google Analytics-->
<script type="text/javascript">

if ("tachesimazzoca.github.io" == location.hostname) {

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-35398490-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
}

</script>
<!--/Google Analytics-->

</body>
</html>

